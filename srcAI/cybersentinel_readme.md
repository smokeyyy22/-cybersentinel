# ğŸ›¡ï¸ CyberSentinel

**AI-Powered Cybersecurity Threat Analysis System**

A locally-runnable, RAG-enhanced threat analysis application that uses open-source LLMs to analyze cybersecurity scenarios and generate detailed reports.

![Version](https://img.shields.io/badge/version-1.0.0-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![Python](https://img.shields.io/badge/python-3.11-blue)
![React](https://img.shields.io/badge/react-18.2-blue)

---

## ğŸ¯ Features

- **ğŸ¤– AI-Powered Analysis**: Uses local LLMs (Llama 3.2, Mistral, etc.) via Ollama
- **ğŸ“š RAG Architecture**: Retrieval-Augmented Generation with ChromaDB vector database
- **ğŸ” Threat Classification**: Automatically categorizes threats (Phishing, Malware, DDoS, etc.)
- **âš ï¸ Severity Assessment**: Assigns Low/Medium/High severity levels
- **ğŸ“‹ Mitigation Advice**: Provides actionable security recommendations
- **ğŸ“„ PDF Reports**: Generate professional threat analysis reports
- **ğŸ¨ Modern UI**: Clean, responsive React interface
- **ğŸ”’ 100% Local**: No cloud APIs, all processing on your machine
- **ğŸ“Š Token Usage Tracking**: Monitor AI model resource consumption
- **ğŸ¯ Interactive Examples**: Quick-start with pre-defined scenarios

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React Frontend â”‚  (Port 3000)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Backendâ”‚  (Port 8000)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼         â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ChromaDBâ”‚ â”‚ Ollama  â”‚ â”‚WeasyPr-â”‚
â”‚ Vector â”‚ â”‚  LLM    â”‚ â”‚  int   â”‚
â”‚   DB   â”‚ â”‚(11434)  â”‚ â”‚  PDF   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components

1. **Frontend (React)**
   - User interface for scenario input
   - Results visualization
   - PDF download functionality

2. **Backend (FastAPI)**
   - REST API endpoints
   - RAG orchestration
   - PDF generation

3. **Vector Database (ChromaDB)**
   - Document embeddings storage
   - Semantic search
   - Context retrieval

4. **LLM (Ollama)**
   - Local model inference
   - Zero cloud dependencies
   - Supports multiple models

---

## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- 8GB+ RAM recommended
- 10GB+ disk space for models

### Installation

1. **Clone/Create the project directory**:
```bash
mkdir cybersentinel && cd cybersentinel
```

2. **Run the automated setup**:
```bash
chmod +x setup.sh
./setup.sh
```

The setup script will:
- Create directory structure
- Install dependencies
- Pull Llama 3.2 model (~2GB)
- Initialize knowledge base
- Start all services

3. **Access the application**:
- Frontend: http://localhost:3000
- API: http://localhost:8000
- API Docs: http://localhost:8000/docs

---

## ğŸ“ Project Structure

```
cybersentinel/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ ingest_documents.py     # Document ingestion script
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â””â”€â”€ Dockerfile             # Backend container
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx            # Main React component
â”‚   â”‚   â”œâ”€â”€ App.css            # Styles
â”‚   â”‚   â”œâ”€â”€ index.js           # Entry point
â”‚   â”‚   â””â”€â”€ index.css          # Global styles
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ index.html         # HTML template
â”‚   â”œâ”€â”€ package.json           # Node dependencies
â”‚   â””â”€â”€ Dockerfile             # Frontend container
â”œâ”€â”€ knowledge_base/            # Cybersecurity documents
â”‚   â”œâ”€â”€ phishing_guide.txt
â”‚   â”œâ”€â”€ malware_response.txt
â”‚   â”œâ”€â”€ ddos_mitigation.txt
â”‚   â””â”€â”€ insider_threats.txt
â”œâ”€â”€ chroma_db/                 # Vector database storage
â”œâ”€â”€ reports/                   # Generated PDF reports
â”œâ”€â”€ docker-compose.yml         # Container orchestration
â”œâ”€â”€ setup.sh                   # Automated setup script
â””â”€â”€ README.md                  # This file
```

---

## ğŸ”§ Manual Setup (Alternative)

If you prefer manual setup:

### 1. Backend Setup

```bash
cd backend
pip install -r requirements.txt

# Create sample data
python ingest_documents.py

# Run backend
python main.py
```

### 2. Frontend Setup

```bash
cd frontend
npm install
npm start
```

### 3. Ollama Setup

```bash
# Install Ollama from https://ollama.ai
ollama pull llama3.2

# Or use another model:
# ollama pull mistral
# ollama pull openhermes
```

---

## ğŸ“– Usage Guide

### Analyzing a Threat

1. **Enter Scenario**: Describe the cybersecurity incident
2. **Click Analyze**: AI processes with RAG context
3. **Review Results**:
   - Threat type classification
   - Severity level
   - Detailed analysis
   - Mitigation steps
   - Source citations
4. **Download Report**: Generate PDF for documentation

### Example Scenarios

**Phishing Attack**:
```
An employee received an email claiming to be from IT support, 
requesting immediate password verification due to a "security breach."
```

**Malware Infection**:
```
Multiple workstations are experiencing unusual CPU spikes, with 
unknown processes communicating with external IP addresses.
```

**DDoS Attack**:
```
Our web application is receiving 50,000 requests per second from 
various geographic locations, causing service degradation.
```

---

## ğŸ¨ Customization

### Adding Custom Documents

1. **Add files to `knowledge_base/`**:
```bash
cp your_document.pdf knowledge_base/
```

2. **Re-ingest documents**:
```bash
docker-compose run --rm backend python ingest_documents.py
```

Supported formats: PDF, TXT, MD

### Changing the LLM Model

Edit `backend/main.py`:
```python
MODEL_NAME = "mistral"  # or "openhermes", "codellama", etc.
```

Then pull the model:
```bash
docker exec cybersentinel-ollama ollama pull mistral
```

### Adjusting RAG Parameters

In `backend/main.py`, modify:
```python
# Number of context chunks to retrieve
results = collection.query(
    query_texts=[query],
    n_results=5  # Increase for more context
)

# Chunk size during ingestion
chunks = chunk_text(text, chunk_size=1000, overlap=100)
```

---

## ğŸ” API Endpoints

### `POST /analyze`
Analyze a threat scenario

**Request**:
```json
{
  "scenario": "Employee clicked suspicious email link..."
}
```

**Response**:
```json
{
  "case_id": "a1b2c3d4",
  "scenario": "Employee clicked suspicious email link...",
  "threat_type": "Phishing",
  "severity": "High",
  "analysis": "This scenario exhibits classic phishing...",
  "recommendations": [
    "Isolate the affected system immediately",
    "Reset user credentials",
    "Scan for malware"
  ],
  "context_sources": ["phishing_guide.txt"],
  "timestamp": "2024-12-11 14:30:00",
  "token_usage": 1250
}
```

### `POST /generate-report`
Generate PDF report (returns PDF file)

### `GET /health`
Check system health

---

## ğŸ³ Docker Commands

```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down

# Rebuild containers
docker-compose up -d --build

# Access backend shell
docker exec -it cybersentinel-backend bash

# Access Ollama
docker exec -it cybersentinel-ollama bash
```

---

## ğŸ”§ Troubleshooting

### Ollama Connection Issues

**Error**: "Cannot connect to Ollama"

**Solution**:
```bash
# Check Ollama status
docker ps | grep ollama

# Restart Ollama
docker-compose restart ollama

# Verify model is pulled
docker exec cybersentinel-ollama ollama list
```

### ChromaDB Not Found

**Error**: "Collection not found"

**Solution**:
```bash
# Re-ingest documents
docker-compose run --rm backend python ingest_documents.py
```

### Frontend Won't Connect

**Error**: "Network error"

**Solution**:
- Ensure backend is running on port 8000
- Check CORS settings in `main.py`
- Verify `API_BASE` in `App.jsx`

### Model Loading Slow

**Issue**: First query takes 1-2 minutes

**Explanation**: Model loading into memory (normal)

**Solution**: Keep Ollama container running

---

## ğŸ“Š Performance Tips

1. **Use Smaller Models**: `llama3.2:1b` for faster responses
2. **Adjust Context**: Reduce `n_results` in RAG queries
3. **GPU Acceleration**: Use Ollama with CUDA support
4. **Increase RAM**: 16GB+ for larger models
5. **SSD Storage**: Faster model loading

---

## ğŸ›¡ï¸ Security Considerations

- **Data Privacy**: All processing is local, no data leaves your machine
- **Access Control**: Add authentication to production deployments
- **Network Isolation**: Use Docker networks for security
- **Input Validation**: Sanitize user inputs in production
- **Rate Limiting**: Add API rate limits for public access

---

## ğŸ”„ Updating

### Update Models
```bash
docker exec cybersentinel-ollama ollama pull llama3.2
```

### Update Dependencies
```bash
docker-compose down
docker-compose up -d --build
```

---

## ğŸ“ Sample Output

### Console Output
```
ğŸ›¡ï¸ Analyzing threat scenario...
âœ“ Retrieved 3 relevant context chunks
âœ“ Generated analysis (1,247 tokens)
âœ“ Classified as: Phishing (High Severity)
âœ“ Generated 5 mitigation recommendations
âœ“ PDF report created: reports/cybersentinel_report_a1b2c3d4.pdf
```

### PDF Report Contents
- Case ID and timestamp
- Threat classification
- Severity badge (color-coded)
- Detailed analysis
- Numbered recommendations
- Source citations
- Token usage statistics

---

## ğŸ¤ Contributing

Contributions welcome! Areas for improvement:

- Additional threat categories
- More knowledge base documents
- Enhanced UI visualizations
- Support for more document types
- Multi-language support
- Historical analysis tracking

---

## ğŸ“„ License

MIT License - feel free to use for any purpose

---

## ğŸ™ Acknowledgments

- **Ollama**: Local LLM runtime
- **ChromaDB**: Vector database
- **FastAPI**: Modern Python API framework
- **React**: UI library
- **WeasyPrint**: PDF generation
- **Sentence Transformers**: Embeddings

---

## ğŸ“ Support

For issues or questions:
1. Check the troubleshooting section
2. Review Docker logs: `docker-compose logs`
3. Ensure all prerequisites are met
4. Verify Ollama model is downloaded

---

## ğŸ¯ Roadmap

- [ ] Multi-model comparison
- [ ] Historical threat tracking
- [ ] Advanced visualization dashboard
- [ ] Export to multiple formats (DOCX, JSON)
- [ ] Integration with SIEM systems
- [ ] Custom threat playbooks
- [ ] Team collaboration features

---

**Built with â¤ï¸ for the cybersecurity community**

*CyberSentinel - Empowering security professionals with local AI*